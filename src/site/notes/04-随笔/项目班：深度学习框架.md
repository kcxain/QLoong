---
{"dg-publish":true,"permalink":"/04-随笔/项目班：深度学习框架/","title":"项目班：深度学习框架"}
---


在自己撸的深度学习框架上跑 transformer！

时隔两年，我终于做完了陈天奇和 J. Zico Kolter 在 CMU 开设的 Deep Learning Systems 课程所有实验。

这门课程着实硬核，内容相当丰富：

1. 自己撸 NDArray 计算库。用 C++ 和 CUDA 实现 NDArray 的 CPU 和 GPU 后端，包括矩阵乘法，Compact，ReduceSum 等，真正做到从零撸深度学习框架
2. 构造计算图，实现自动求导机制。推导并实现常见算子的正向与反向传播，除一些基础运算外，还包括 broadcast_to，summation 甚至卷积操作 conv 等
3. 实现深度学习时代的常见模块。包括 Adam 优化器、BatchNorm/LayerNorm、Dropout 以及 DataLoader 等工具类
4. 在自己的框架上实现并跑通 ResNet，CNN，RNN，LSTM，Transformer

没错！我们做的框架不仅仅是个玩具，它真正能将现有的经典网络跑起来，并且理论上不需要依赖任何外部库（很多人做的深度学习框架项目底层都是 Numpy）。

非常建议所有 AI 相关的考研/找工作的同学做一做这个项目。当前 Pytorch/transformers 太过强大，以至于人人都能通过调库轻松完成“高大上”的 AI 项目。对于这些调库调参的项目，各高校的老师/面试官恐怕早已厌烦。当他人简历上都是千篇一律的“xxx 图像识别、情感分类···”时，你的简历只需轻描淡写一句“在自己的深度学习框架上跑 transformer 实现机器翻译”定能让老师眼前一亮！

我曾在其他平台分享前两个实验的详细解析，未来有时间会继续更新！
